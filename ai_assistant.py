# -*- coding: utf-8 -*-
import os
import sys
import json
from datetime import datetime
from pathlib import Path
from openai import OpenAI
from anthropic import Anthropic
from typing import List, Dict, Optional, Union

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è Windows –∫–æ–Ω—Å–æ–ª–∏
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
from config import (
    PROXY_API_KEY,
    OPENAI_BASE_URL,
    ANTHROPIC_BASE_URL,
    PROXY_SUPPORTS_REASONING
)
from logger import log_error, log_request
import time

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç OpenAI —Å –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä–æ–º
openai_client = OpenAI(
    api_key=PROXY_API_KEY,
    base_url=OPENAI_BASE_URL
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç Anthropic (Claude) —Å –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä–æ–º
anthropic_client = Anthropic(
    api_key=PROXY_API_KEY,
    base_url=ANTHROPIC_BASE_URL
)


class ChatAssistant:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Chat Completions API —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–∏–∞–ª–æ–≥–∞.
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.
    –ò—Å—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ —Ñ–∞–π–ª –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è.
    """
    
    def __init__(self, model: str = "gpt-3.5-turbo", system_message: str = "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.", 
                 history_file: Optional[str] = "chat_history.json", temperature: float = 1.0):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.
        
        Args:
            model: –ú–æ–¥–µ–ª—å OpenAI –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é gpt-3.5-turbo)
            system_message: –°–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
            history_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ (None - –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ —Ñ–∞–π–ª)
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ (0.0-2.0, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1.0)
        """
        self.model = model
        self.history_file = history_file
        self.temperature = temperature
        self.messages: List[Dict[str, str]] = [
            {"role": "system", "content": system_message}
        ]
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –∏–∑ —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –æ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if self.history_file:
            self.load_history()
            # –ï—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ –±—ã–ª–æ, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            if not Path(self.history_file).exists():
                self.save_history()
    
    def add_message(self, role: str, content: str):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ —Ñ–∞–π–ª.
        
        Args:
            role: –†–æ–ª—å –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è ('user', 'assistant', 'system')
            content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        """
        self.messages.append({"role": role, "content": content})
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        if self.history_file:
            self.save_history()
    
    def is_claude_model(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª—å Claude (Anthropic)"""
        claude_models = ["claude", "sonnet"]
        return any(model in self.model.lower() for model in claude_models)
    
    def get_response(self, user_message: str, reasoning_effort: Optional[str] = None, 
                     reasoning_summary: Optional[str] = None) -> tuple[str, Optional[Dict]]:
        """
        –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –ø–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
        
        Args:
            user_message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            reasoning_effort: –£—Ä–æ–≤–µ–Ω—å reasoning –¥–ª—è self-reasoning –º–æ–¥–µ–ª–µ–π 
                             ('minimal', 'low', 'medium', 'high')
            reasoning_summary: –¢–∏–ø summary –¥–ª—è reasoning ('auto', 'concise', 'detailed')
            
        Returns:
            tuple: (–û—Ç–≤–µ—Ç –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞, –ú–µ—Ç—Ä–∏–∫–∏ reasoning –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)
        """
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.add_message("user", user_message)
        
        reasoning_metrics = None
        
        try:
            if self.is_claude_model():
                # –†–∞–±–æ—Ç–∞ —Å Claude (Anthropic)
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è Claude (—Ñ–æ—Ä–º–∞—Ç –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç OpenAI)
                claude_messages = []
                system_message = None
                
                for msg in self.messages:
                    if msg["role"] == "system":
                        system_message = msg["content"]
                    elif msg["role"] in ["user", "assistant"]:
                        claude_messages.append({
                            "role": msg["role"],
                            "content": msg["content"]
                        })
                
                # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
                request_params = {
                    "model": self.model,
                    "max_tokens": 4096,
                    "messages": claude_messages,
                    "system": system_message if system_message else None
                }
                
                # –ó–∞—Å–µ–∫–∞–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞
                start_time = time.time()
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ Claude API
                response = anthropic_client.messages.create(**request_params)
                
                response_time = time.time() - start_time
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç
                assistant_message = response.content[0].text
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º reasoning –º–µ—Ç—Ä–∏–∫–∏, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
                tokens_info = None
                if hasattr(response, 'usage') and response.usage:
                    reasoning_metrics = {
                        "input_tokens": getattr(response.usage, 'input_tokens', 0),
                        "output_tokens": getattr(response.usage, 'output_tokens', 0),
                        "cache_creation_input_tokens": getattr(response.usage, 'cache_creation_input_tokens', 0),
                        "cache_read_input_tokens": getattr(response.usage, 'cache_read_input_tokens', 0),
                    }
                    tokens_info = {
                        "input_tokens": reasoning_metrics["input_tokens"],
                        "output_tokens": reasoning_metrics["output_tokens"]
                    }
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ reasoning –º–µ—Ç—Ä–∏–∫ –≤ response
                if hasattr(response, 'stop_reason'):
                    reasoning_metrics = reasoning_metrics or {}
                    reasoning_metrics["stop_reason"] = response.stop_reason
                
                # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–π –∑–∞–ø—Ä–æ—Å
                log_request(
                    service="Anthropic",
                    model=self.model,
                    params=request_params,
                    response_time=response_time,
                    tokens=tokens_info
                )
                
            else:
                # –†–∞–±–æ—Ç–∞ —Å OpenAI –º–æ–¥–µ–ª—è–º–∏
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
                request_params = {
                    "model": self.model,
                    "messages": self.messages,
                    "temperature": self.temperature
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º reasoning_effort –¥–ª—è self-reasoning –º–æ–¥–µ–ª–µ–π (gpt-5, o-series)
                # –í–ê–ñ–ù–û: –ü—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä api.proxyapi.ru –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç reasoning_effort
                # –ü–∞—Ä–∞–º–µ—Ç—Ä –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø—Ä–æ–∫—Å–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç reasoning
                if reasoning_effort and PROXY_SUPPORTS_REASONING:
                    request_params["reasoning_effort"] = reasoning_effort
                elif reasoning_effort and not PROXY_SUPPORTS_REASONING:
                    # –î–ª—è –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä–∞ reasoning –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è
                    # –ú–æ–¥–µ–ª—å –≤—Å–µ —Ä–∞–≤–Ω–æ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å, –Ω–æ –±–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö reasoning –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                    pass
                
                # –ó–∞—Å–µ–∫–∞–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞
                start_time = time.time()
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ API
                response = openai_client.chat.completions.create(**request_params)
                
                response_time = time.time() - start_time
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
                assistant_message = response.choices[0].message.content
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º usage –º–µ—Ç—Ä–∏–∫–∏
                tokens_info = None
                if hasattr(response, 'usage') and response.usage:
                    reasoning_metrics = {
                        "prompt_tokens": getattr(response.usage, 'prompt_tokens', 0),
                        "completion_tokens": getattr(response.usage, 'completion_tokens', 0),
                        "total_tokens": getattr(response.usage, 'total_tokens', 0),
                    }
                    tokens_info = {
                        "total_tokens": reasoning_metrics["total_tokens"],
                        "prompt_tokens": reasoning_metrics["prompt_tokens"],
                        "completion_tokens": reasoning_metrics["completion_tokens"]
                    }
                
                # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–π –∑–∞–ø—Ä–æ—Å
                log_request(
                    service="OpenAI",
                    model=self.model,
                    params=request_params,
                    response_time=response_time,
                    tokens=tokens_info
                )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é
            self.add_message("assistant", assistant_message)
            
            return assistant_message, reasoning_metrics
        
        except Exception as e:
            # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            log_error(e, context={
                "model": self.model,
                "is_claude": self.is_claude_model(),
                "temperature": self.temperature,
                "messages_count": len(self.messages)
            })
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}", None
    
    def clear_history(self, keep_system: bool = True):
        """
        –û—á–∏—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞.
        
        Args:
            keep_system: –ï—Å–ª–∏ True, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        """
        if keep_system:
            self.messages = [self.messages[0]]  # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        else:
            self.messages = []
    
    def get_history(self) -> List[Dict[str, str]]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞.
        
        Returns:
            –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –¥–∏–∞–ª–æ–≥–µ
        """
        return self.messages.copy()
    
    def save_history(self, language: str = None):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ –≤ JSON —Ñ–∞–π–ª.
        
        Args:
            language: –ö–æ–¥ —è–∑—ã–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –ø—ã—Ç–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–∑ context_manager)
        """
        if not self.history_file:
            return
        
        try:
            # –ï—Å–ª–∏ —è–∑—ã–∫ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω, –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –µ–≥–æ –∏–∑ context_manager –ø–æ user_id –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            if language is None and self.history_file:
                try:
                    import re
                    from context_manager import get_user_language
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º user_id –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ chat_history_{user_id}.json
                    match = re.search(r'chat_history_(\d+)\.json', self.history_file)
                    if match:
                        user_id = int(match.group(1))
                        language = get_user_language(user_id)
                except Exception:
                    pass  # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —è–∑—ã–∫, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –±–µ–∑ –Ω–µ–≥–æ
            
            history_data = {
                "model": self.model,
                "temperature": self.temperature,
                "last_updated": datetime.now().isoformat(),
                "messages": self.messages
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º —è–∑—ã–∫, –µ—Å–ª–∏ –æ–Ω –¥–æ—Å—Ç—É–ø–µ–Ω
            if language:
                history_data["language"] = language
            
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(history_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            log_error(e, context={"action": "save_history", "file": self.history_file})
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏: {str(e)}")
    
    
    def load_history(self):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ –∏–∑ JSON —Ñ–∞–π–ª–∞.
        
        Returns:
            str: –ö–æ–¥ —è–∑—ã–∫–∞ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –∏–ª–∏ None
        """
        if not self.history_file or not Path(self.history_file).exists():
            return None
        
        try:
            with open(self.history_file, 'r', encoding='utf-8') as f:
                history_data = json.load(f)
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
                if "messages" in history_data and history_data["messages"]:
                    self.messages = history_data["messages"]
                # –û–±–Ω–æ–≤–ª—è–µ–º –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –æ–Ω–∞ —É–∫–∞–∑–∞–Ω–∞ –≤ —Ñ–∞–π–ª–µ
                if "model" in history_data:
                    self.model = history_data["model"]
                # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É, –µ—Å–ª–∏ –æ–Ω–∞ —É–∫–∞–∑–∞–Ω–∞ –≤ —Ñ–∞–π–ª–µ
                if "temperature" in history_data:
                    self.temperature = history_data["temperature"]
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —è–∑—ã–∫, –µ—Å–ª–∏ –æ–Ω —É–∫–∞–∑–∞–Ω –≤ —Ñ–∞–π–ª–µ
                return history_data.get("language")
        except Exception as e:
            log_error(e, context={"action": "load_history", "file": self.history_file})
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏—Å—Ç–æ—Ä–∏–∏: {str(e)}")
            return None
    
    def export_history_to_text(self, output_file: str = "chat_history.txt"):
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è.
        
        Args:
            output_file: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É
        """
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("=== –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ ===\n\n")
                for i, msg in enumerate(self.messages, 1):
                    role_name = {
                        "system": "–°–∏—Å—Ç–µ–º–∞",
                        "user": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å",
                        "assistant": "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"
                    }.get(msg["role"], msg["role"])
                    
                    f.write(f"{i}. [{role_name}]\n{msg['content']}\n\n")
                    f.write("-" * 50 + "\n\n")
            
            print(f"–ò—Å—Ç–æ—Ä–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤ —Ñ–∞–π–ª: {output_file}")
        except Exception as e:
            log_error(e, context={"action": "export_history", "file": output_file})
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –∏—Å—Ç–æ—Ä–∏–∏: {str(e)}")


def simple_chat(model: str = "gpt-3.5-turbo", system_message: str = "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.") -> str:
    """
    –ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–¥–Ω–æ–∫—Ä–∞—Ç–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
    
    Args:
        model: –ú–æ–¥–µ–ª—å OpenAI –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        system_message: –°–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        
    Returns:
        –û—Ç–≤–µ—Ç –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    """
    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç!"}
    ]
    
    try:
        response = openai_client.chat.completions.create(
            model=model,
            messages=messages
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"–û—à–∏–±–∫–∞: {str(e)}"


# –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –¥–∏–∞–ª–æ–≥
def interactive_chat():
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –¥–∏–∞–ª–æ–≥ —Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º.
    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –≤–≤–æ–¥–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è, –∏—Å—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.
    """
    print("=== –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –¥–∏–∞–ª–æ–≥ —Å AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º ===\n")
    print("–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
    print("  OpenAI:")
    print("    - gpt-3.5-turbo (–±—ã—Å—Ç—Ä–∞—è, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è)")
    print("    - gpt-4o (–ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è)")
    print("    - gpt-5-pro (self-reasoning, –≤—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å reasoning)")
    print("    - o1, o3 (self-reasoning –º–æ–¥–µ–ª–∏)")
    print("  Anthropic (Claude):")
    print("    - claude-sonnet-4-5-20250929 (Claude 4.5 Sonnet —Å reasoning –º–µ—Ç—Ä–∏–∫–∞–º–∏)")
    print()
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    model_choice = input("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å (Enter –¥–ª—è claude-sonnet-4-5-20250929): ").strip()
    if not model_choice:
        model_choice = "claude-sonnet-4-5-20250929"
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ reasoning –¥–ª—è self-reasoning –º–æ–¥–µ–ª–µ–π
    reasoning_models = ["gpt-5-pro", "gpt-5", "o1", "o3", "o1-preview", "o3-mini"]
    use_reasoning = any(model in model_choice.lower() for model in reasoning_models)
    
    reasoning_effort = None
    reasoning_summary = None
    
    if use_reasoning:
        print("\n–ù–∞—Å—Ç—Ä–æ–π–∫–∞ self-reasoning:")
        if not PROXY_SUPPORTS_REASONING:
            print("‚ö† –í–Ω–∏–º–∞–Ω–∏–µ: –ü—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç reasoning –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.")
            print("–ú–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å, –Ω–æ –±–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö reasoning –Ω–∞—Å—Ç—Ä–æ–µ–∫.\n")
        effort_choice = input("–£—Ä–æ–≤–µ–Ω—å reasoning effort (minimal/low/medium/high, Enter –¥–ª—è high): ").strip()
        reasoning_effort = effort_choice if effort_choice else "high"
        reasoning_summary = None  # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, —Ç–∞–∫ –∫–∞–∫ –º–æ–∂–µ—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å—Å—è –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä–æ–º
    
    # –°–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
    system_msg = "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –û—Ç–≤–µ—á–∞–π –ø–æ–¥—Ä–æ–±–Ω–æ –∏ –ø–æ–ª–µ–∑–Ω–æ."
    
    # –°–æ–∑–¥–∞–µ–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    assistant = ChatAssistant(
        model=model_choice,
        system_message=system_msg
    )
    
    print(f"\n‚úì –ú–æ–¥–µ–ª—å: {model_choice}")
    if assistant.is_claude_model():
        print("‚úì –ü—Ä–æ–≤–∞–π–¥–µ—Ä: Anthropic (Claude)")
        print("‚úì Reasoning –º–µ—Ç—Ä–∏–∫–∏ –±—É–¥—É—Ç –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å—Å—è –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –æ—Ç–≤–µ—Ç–∞")
    else:
        print("‚úì –ü—Ä–æ–≤–∞–π–¥–µ—Ä: OpenAI")
    if use_reasoning:
        print(f"‚úì Reasoning effort: {reasoning_effort}")
    print(f"‚úì –ò—Å—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤: {assistant.history_file}")
    print("\n" + "="*60)
    print("–ù–∞—á–Ω–∏—Ç–µ –¥–∏–∞–ª–æ–≥! (–≤–≤–µ–¥–∏—Ç–µ 'exit' –∏–ª–∏ 'quit' –¥–ª—è –≤—ã—Ö–æ–¥–∞)")
    print("–ö–æ–º–∞–Ω–¥—ã: 'export' –∏–ª–∏ 'save' - —ç–∫—Å–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª")
    print("="*60 + "\n")
    
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –¥–∏–∞–ª–æ–≥–∞
    while True:
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_input = input("–í—ã: ").strip()
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤—ã—Ö–æ–¥
            if user_input.lower() in ['exit', 'quit', '–≤—ã—Ö–æ–¥', '—Å—Ç–æ–ø']:
                print("\n=== –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞ ===")
                print(f"–ò—Å—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {assistant.history_file}")
                break
            
            # –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –∏—Å—Ç–æ—Ä–∏–∏ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
            if user_input.lower() in ['export', '—ç–∫—Å–ø–æ—Ä—Ç', 'save', '—Å–æ—Ö—Ä–∞–Ω–∏—Ç—å']:
                assistant.export_history_to_text("chat_history.txt")
                print("–ò—Å—Ç–æ—Ä–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤: chat_history.txt\n")
                continue
            
            if not user_input:
                continue
            
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
            print("\n–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥—É–º–∞–µ—Ç...")
            if use_reasoning:
                response, metrics = assistant.get_response(
                    user_input, 
                    reasoning_effort=reasoning_effort
                )
            else:
                response, metrics = assistant.get_response(user_input)
            
            print(f"–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: {response}\n")
            
            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º reasoning –º–µ—Ç—Ä–∏–∫–∏, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
            if metrics:
                print("üìä Reasoning –º–µ—Ç—Ä–∏–∫–∏:")
                if assistant.is_claude_model():
                    print(f"   ‚Ä¢ –í—Ö–æ–¥–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã: {metrics.get('input_tokens', 'N/A')}")
                    print(f"   ‚Ä¢ –í—ã—Ö–æ–¥–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã: {metrics.get('output_tokens', 'N/A')}")
                    if metrics.get('cache_creation_input_tokens'):
                        print(f"   ‚Ä¢ –¢–æ–∫–µ–Ω—ã —Å–æ–∑–¥–∞–Ω–∏—è –∫—ç—à–∞: {metrics.get('cache_creation_input_tokens', 'N/A')}")
                    if metrics.get('cache_read_input_tokens'):
                        print(f"   ‚Ä¢ –¢–æ–∫–µ–Ω—ã —á—Ç–µ–Ω–∏—è –∫—ç—à–∞: {metrics.get('cache_read_input_tokens', 'N/A')}")
                    if metrics.get('stop_reason'):
                        print(f"   ‚Ä¢ –ü—Ä–∏—á–∏–Ω–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏: {metrics.get('stop_reason', 'N/A')}")
                else:
                    print(f"   ‚Ä¢ –ü—Ä–æ–º–ø—Ç —Ç–æ–∫–µ–Ω—ã: {metrics.get('prompt_tokens', 'N/A')}")
                    print(f"   ‚Ä¢ –¢–æ–∫–µ–Ω—ã –æ—Ç–≤–µ—Ç–∞: {metrics.get('completion_tokens', 'N/A')}")
                    print(f"   ‚Ä¢ –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {metrics.get('total_tokens', 'N/A')}")
                print()
            
            print("-" * 60 + "\n")
            
        except KeyboardInterrupt:
            print("\n\n=== –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º ===")
            print(f"–ò—Å—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {assistant.history_file}")
            break
        except Exception as e:
            print(f"\n–û—à–∏–±–∫–∞: {str(e)}\n")


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –¥–∏–∞–ª–æ–≥
    interactive_chat()

